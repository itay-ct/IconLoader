{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Lucide Icon Loader - Vector Search Indexer\n",
    "\n",
    "This notebook fetches Lucide icon metadata, generates semantic embeddings, and stores them in Redis for vector search.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/IconLoader/blob/main/IconLoader.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "First, install all required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers redisvl redis requests numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_header"
   },
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set your Redis URL and other configuration options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Get Redis URL securely (won't be saved in notebook)\n",
    "REDIS_URL = getpass('Enter your Redis URL (e.g., redis://default:password@host:6379): ')\n",
    "\n",
    "# Configuration\n",
    "INDEX_NAME = \"lucide_icon_index\"\n",
    "KEY_PREFIX = \"lucide:icon:\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMBEDDING_DIM = 384\n",
    "LUCIDE_RAW_BASE = \"https://raw.githubusercontent.com/lucide-icons/lucide/main/icons/\"\n",
    "\n",
    "# Test sentences\n",
    "TEST_SENTENCES = [\n",
    "    \"Found 5 places offering a relaxing drink for your tour.\",\n",
    "    \"I found 9 parks to enjoy nature's beauty nearby.\",\n",
    "    \"There are 3 locations of cultural interest, ready to inspire.\",\n",
    "    \"Found 8 exciting sports and activity locations around.\",\n",
    "    \"Found 17 delicious food spots awaiting your hungry stomach.\",\n",
    "    \"Discovered 4 historical landmarks worth visiting.\",\n",
    "    \"Located 6 shopping centers for your retail therapy.\",\n",
    "    \"Found 12 entertainment venues for a fun night out.\",\n",
    "    \"There are 7 hotels offering comfortable accommodation.\",\n",
    "    \"Spotted 10 scenic viewpoints for amazing photos.\"\n",
    "]\n",
    "\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icons_header"
   },
   "source": [
    "## 3. Icon List\n",
    "\n",
    "Define which icons to load (or upload icons.txt file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icons"
   },
   "outputs": [],
   "source": [
    "# Option 1: Upload icons.txt file\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"Upload your icons.txt file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'icons.txt' in uploaded:\n",
    "    icon_slugs = uploaded['icons.txt'].decode('utf-8').strip().split('\\n')\n",
    "    icon_slugs = [s.strip() for s in icon_slugs if s.strip() and not s.startswith('#')]\n",
    "    print(f\"✓ Loaded {len(icon_slugs)} icons from file\")\n",
    "else:\n",
    "    # Option 2: Define icons directly\n",
    "    icon_slugs = [\n",
    "        \"beer\", \"wine\", \"coffee\", \"martini\",\n",
    "        \"trees\", \"tree-palm\", \"tent\",\n",
    "        \"building-2\", \"landmark\", \"church\",\n",
    "        \"binoculars\", \"locate\", \"navigation\",\n",
    "        \"ice-cream-cone\", \"salad\", \"popcorn\"\n",
    "    ]\n",
    "    print(f\"✓ Using {len(icon_slugs)} predefined icons\")\n",
    "\n",
    "print(f\"Icons to process: {', '.join(icon_slugs[:10])}{'...' if len(icon_slugs) > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "functions_header"
   },
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Define all the helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "functions"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "def slug_to_component_name(slug: str) -> str:\n",
    "    \"\"\"Convert icon slug to component name (e.g., 'a-arrow-down' -> 'AArrowDown')\"\"\"\n",
    "    parts = slug.split('-')\n",
    "    return ''.join(p.capitalize() for p in parts)\n",
    "\n",
    "def fetch_icon_metadata(slug: str) -> dict:\n",
    "    \"\"\"Fetch icon metadata JSON from Lucide GitHub\"\"\"\n",
    "    url = f\"{LUCIDE_RAW_BASE}{slug}.json\"\n",
    "    resp = requests.get(url, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def build_description(name: str, slug: str, tags: List[str]) -> str:\n",
    "    \"\"\"Build a semantically rich description string to embed\"\"\"\n",
    "    tag_str = \", \".join(tags) if tags else \"icon\"\n",
    "    base = f\"{name} - {slug}; {tag_str}\"\n",
    "    return base\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "redis_header"
   },
   "source": [
    "## 5. Connect to Redis & Create Index\n",
    "\n",
    "Connect to Redis and set up the vector index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "redis"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "print(\"Connecting to Redis...\")\n",
    "redis_client = redis.from_url(REDIS_URL)\n",
    "\n",
    "# Test connection\n",
    "redis_client.ping()\n",
    "print(\"✓ Connected to Redis\")\n",
    "\n",
    "# Clean existing lucide:* keys\n",
    "print(\"\\nCleaning existing lucide:* keys...\")\n",
    "keys = redis_client.keys(\"lucide:*\")\n",
    "if keys:\n",
    "    redis_client.delete(*keys)\n",
    "    print(f\"✓ Deleted {len(keys)} existing keys\")\n",
    "else:\n",
    "    print(\"✓ No existing keys to delete\")\n",
    "\n",
    "# Create index\n",
    "print(\"\\nCreating vector index...\")\n",
    "index_config = {\n",
    "    \"index\": {\n",
    "        \"name\": INDEX_NAME,\n",
    "        \"prefix\": KEY_PREFIX,\n",
    "        \"storage_type\": \"hash\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"name\", \"type\": \"tag\"},\n",
    "        {\"name\": \"description\", \"type\": \"text\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": EMBEDDING_DIM,\n",
    "                \"algorithm\": \"flat\",\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"datatype\": \"float32\",\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "index = SearchIndex.from_dict(index_config)\n",
    "index.set_client(redis_client)\n",
    "\n",
    "if not index.exists():\n",
    "    index.create()\n",
    "    print(f\"✓ Created index '{INDEX_NAME}'\")\n",
    "else:\n",
    "    print(f\"✓ Using existing index '{INDEX_NAME}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_header"
   },
   "source": [
    "## 6. Load Model & Process Icons\n",
    "\n",
    "Load the embedding model and process all icons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"Loading embedding model: {EMBEDDING_MODEL_NAME}...\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "print(\"✓ Model loaded\\n\")\n",
    "\n",
    "docs = []\n",
    "\n",
    "for i, slug in enumerate(icon_slugs, 1):\n",
    "    component_name = slug_to_component_name(slug)\n",
    "    \n",
    "    print(f\"[{i}/{len(icon_slugs)}] Processing '{slug}' ({component_name})...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        # Fetch metadata\n",
    "        meta = fetch_icon_metadata(slug)\n",
    "        tags = meta.get(\"tags\", [])\n",
    "        if not isinstance(tags, list):\n",
    "            tags = list(tags) if tags else []\n",
    "        \n",
    "        # Build description\n",
    "        description = build_description(component_name, slug, tags)\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding_vector = model.encode(description, show_progress_bar=False).tolist()\n",
    "        \n",
    "        if len(embedding_vector) != EMBEDDING_DIM:\n",
    "            raise ValueError(f\"Embedding dimension mismatch: expected {EMBEDDING_DIM}, got {len(embedding_vector)}\")\n",
    "        \n",
    "        # Convert to bytes\n",
    "        embedding_bytes = np.array(embedding_vector, dtype=np.float32).tobytes()\n",
    "        \n",
    "        # Create document\n",
    "        doc = {\n",
    "            \"name\": slug,\n",
    "            \"description\": description,\n",
    "            \"embedding\": embedding_bytes,\n",
    "        }\n",
    "        docs.append(doc)\n",
    "        \n",
    "        print(\"✓\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "\n",
    "print(f\"\\n✓ Processed {len(docs)} icons successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "index_header"
   },
   "source": [
    "## 7. Index Icons in Redis\n",
    "\n",
    "Store all processed icons in the Redis vector index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index_data"
   },
   "outputs": [],
   "source": [
    "if docs:\n",
    "    print(f\"Indexing {len(docs)} icons into Redis...\")\n",
    "    index.load(docs)\n",
    "    print(\"✓ Done indexing Lucide icons\")\n",
    "else:\n",
    "    print(\"⚠ No icons to index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## 8. Test Vector Search\n",
    "\n",
    "Run test queries to verify the vector search is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test"
   },
   "outputs": [],
   "source": [
    "from redisvl.query import VectorQuery\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing vector search with sample sentences...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "for i, sentence in enumerate(TEST_SENTENCES, 1):\n",
    "    # Encode the test sentence\n",
    "    query_embedding = model.encode(sentence, show_progress_bar=False).tolist()\n",
    "    query_bytes = np.array(query_embedding, dtype=np.float32).tobytes()\n",
    "    \n",
    "    # Perform vector search (top 1 result)\n",
    "    query = VectorQuery(\n",
    "        vector=query_bytes,\n",
    "        vector_field_name=\"embedding\",\n",
    "        return_fields=[\"name\", \"description\"],\n",
    "        num_results=1\n",
    "    )\n",
    "    \n",
    "    results = index.query(query)\n",
    "    \n",
    "    if results:\n",
    "        top_icon = results[0].get(\"name\", \"N/A\")\n",
    "        print(f\"[Test {i}] \\\"{sentence}\\\" => {top_icon}\")\n",
    "    else:\n",
    "        print(f\"[Test {i}] \\\"{sentence}\\\" => No results found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ Testing complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_search_header"
   },
   "source": [
    "## 9. Custom Search (Optional)\n",
    "\n",
    "Try your own search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_search"
   },
   "outputs": [],
   "source": [
    "# Enter your custom query\n",
    "custom_query = input(\"Enter your search query: \")\n",
    "\n",
    "if custom_query:\n",
    "    query_embedding = model.encode(custom_query, show_progress_bar=False).tolist()\n",
    "    query_bytes = np.array(query_embedding, dtype=np.float32).tobytes()\n",
    "    \n",
    "    query = VectorQuery(\n",
    "        vector=query_bytes,\n",
    "        vector_field_name=\"embedding\",\n",
    "        return_fields=[\"name\", \"description\"],\n",
    "        num_results=5\n",
    "    )\n",
    "    \n",
    "    results = index.query(query)\n",
    "    \n",
    "    print(f\"\\nTop 5 results for: \\\"{custom_query}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, result in enumerate(results, 1):\n",
    "        name = result.get(\"name\", \"N/A\")\n",
    "        description = result.get(\"description\", \"N/A\")\n",
    "        score = result.get(\"vector_distance\", \"N/A\")\n",
    "        print(f\"{i}. {name} (score: {score})\")\n",
    "        print(f\"   {description}\")\n",
    "else:\n",
    "    print(\"No query entered\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "IconLoader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

